---
title: 梯度下降与LMS算法
date: 2017-04-24
categories:
- 机器学习/斯坦福系列课程
tags:
- 梯度下降
- LMS
- 批梯度下降
- 随机梯度下降
---



由[监督学习与线性回归](http://lhmachine.top/wordpress/?p=115#more-115)一节可知，$\theta=argminJ(\theta)$，则可以设计如下的搜寻算法来获取$\theta$的值。

​		(1)设定初始$\theta$值，假设$\vec \theta=\vec 0$；

​		(2)重复改变$\theta$使得$J(\theta)$更小，直到$J(\theta)$最小时候收敛。

特定的，对于**梯度下降**算法，设定初始$\theta$值后，其重复更新规则如下：

$$ \theta_j=\theta_j-\alpha \frac\partial{\partial\theta_j}J(\theta) $$，j=0,1,……,n（对所有j同时更新）

式中，$\alpha$为学习率。该更新规则公式每次更新朝着$J$下降最为陡峭的方向进行。

为了简化$J(\theta)$中的累加符号，以便计算上式右边的偏微分，我们只考虑单个训练样本时的情况。则此时偏微分公式计算如下：

$$ \frac\partial{\partial\theta_j}J(\theta)=\frac\partial{\partial\theta_j}\frac12(h_\theta(\vec x)-y)^2=2·\frac12(h_\theta(\vec x)-y)·\frac\partial{\partial\theta_j}(h_\theta(\vec x)-y) $$

$$ =(h_\theta(\vec x)-y)·\frac\partial{\partial\theta_j}(\sum_{i=0}^n\theta_ix_i-y)=(h_\theta(\vec x)-y)x_j $$

即对于单个训练样本而言，$\theta$值的更新规则可表示为：

$$ \theta_j=\theta_j-\alpha(h_\theta(\vec x)-y)x_j $$

该规则成为**LMS算法**(Least Mean Square，最小均方值)，也成为**Widrow-Hoff**算法。式中，$\alpha$的值通常是**预设的，既不能太大也不能太小**。若太小，则每次更新幅度也较小，收敛时间会更长；若太大，则每次更新幅度较大，可能导致越过最小值。

由此可知，该规则具有如下的性质：**更新的幅度与误差项$y^{(i)}-h_\theta(x^{(i)})$成比例**。深言之，当我们对样本的预测值与实际值几乎相匹配，只需要小小的更新下参数。相反，当$h_\theta(x)$与$y^{(i)}$有较大的误差时，参数即需要更新较大。

我们既然考虑了单个训练样本情况下的更新规则，并由此得到LMS算法。紧接着，我们可以推导出多训练样本下的更新规则。

当训练集中有超过一个的训练样本时，有两种途径去修改这个方法。

1）**批梯度下降**（Batch Gradient Descent）

更新规则如下：

$$ \theta_j=\theta_j-\alpha\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}，j=0,1,...,n $$

观察上式可以看出，其更新仅在于$\frac{\partial J(\theta)}{\partial\theta_j}$，所以该更新只是在代价函数$J$上简单的梯度下降。

注意，当m值很大时，批梯度下降在每次更新之前需要扫描全部的训练集。

2）**随机梯度下降**（Stochastic Gradient Descent）

也称为增值梯度下降，其更新规则如下：

Loop{

for  i=1 to m,{

$$ \theta_j=\theta_j+\alpha(y^{(i)}-h_\theta(x^{(i)}))x_j^{(i)} $$，对每一个j，j=0,1,...,n

}

}

​无论m多大，随机梯度下降算法都可以立即开始并持续的更新每一个正在处理的样本。需要注意的是，尽管随机梯度下降可能从不收敛到最小值，但它总是在最小值周围保持震荡。实际上，大多数接近最小值的值相对于真正的最小值而言都是足够相似好。然而在运行随机梯度下降算法时，我们通过使用慢慢减小学习率$\alpha$到0，以描述随机梯度下降也是很常见的。这也能够确保参数将收敛到全局最小而不仅仅只是在最小值周围震荡。